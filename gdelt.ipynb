{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 22:47:13,194 - DEBUG - Starting new HTTPS connection (1): api.gdeltproject.org:443\n",
      "2024-12-01 22:47:14,157 - DEBUG - https://api.gdeltproject.org:443 \"GET /api/v2/doc/doc?query=election+sourcecountry%3Aunitedstates+sourcelang%3Aenglish&startdatetime=20241006000000&enddatetime=20241105235959&mode=artlist&format=json&maxrecords=250 HTTP/11\" 200 None\n",
      "2024-12-01 22:47:14,243 - INFO - Data fetched successfully for election from GDELT API.\n",
      "2024-12-01 22:47:14,273 - DEBUG - Starting new HTTPS connection (1): api.gdeltproject.org:443\n",
      "2024-12-01 22:47:15,054 - DEBUG - https://api.gdeltproject.org:443 \"GET /api/v2/doc/doc?query=business+sourcecountry%3Aunitedstates+sourcelang%3Aenglish&startdatetime=20241006000000&enddatetime=20241105235959&mode=artlist&format=json&maxrecords=250 HTTP/11\" 200 None\n",
      "2024-12-01 22:47:15,164 - INFO - Data fetched successfully for business from GDELT API.\n",
      "2024-12-01 22:47:15,190 - DEBUG - Starting new HTTPS connection (1): api.gdeltproject.org:443\n",
      "2024-12-01 22:47:15,727 - DEBUG - https://api.gdeltproject.org:443 \"GET /api/v2/doc/doc?query=finance+sourcecountry%3Aunitedstates+sourcelang%3Aenglish&startdatetime=20241006000000&enddatetime=20241105235959&mode=artlist&format=json&maxrecords=250 HTTP/11\" 200 None\n",
      "2024-12-01 22:47:15,821 - INFO - Data fetched successfully for finance from GDELT API.\n",
      "2024-12-01 22:47:15,825 - DEBUG - Starting new HTTPS connection (1): api.gdeltproject.org:443\n",
      "2024-12-01 22:47:16,477 - DEBUG - https://api.gdeltproject.org:443 \"GET /api/v2/doc/doc?query=health+sourcecountry%3Aunitedstates+sourcelang%3Aenglish&startdatetime=20241006000000&enddatetime=20241105235959&mode=artlist&format=json&maxrecords=250 HTTP/11\" 200 None\n",
      "2024-12-01 22:47:16,556 - INFO - Data fetched successfully for health from GDELT API.\n",
      "2024-12-01 22:47:16,578 - DEBUG - Starting new HTTPS connection (1): api.gdeltproject.org:443\n",
      "2024-12-01 22:47:17,152 - DEBUG - https://api.gdeltproject.org:443 \"GET /api/v2/doc/doc?query=environment+sourcecountry%3Aunitedstates+sourcelang%3Aenglish&startdatetime=20241006000000&enddatetime=20241105235959&mode=artlist&format=json&maxrecords=250 HTTP/11\" 200 None\n",
      "2024-12-01 22:47:17,240 - INFO - Data fetched successfully for environment from GDELT API.\n",
      "2024-12-01 22:47:17,635 - INFO - CSV data saved successfully for all topics.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up logging to track errors\n",
    "log_directory = \"logs\"\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "\n",
    "# Configure logging to log to both file and console\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# File handler for logging to a file\n",
    "file_handler = logging.FileHandler(f\"{log_directory}/debug_log.txt\")\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "\n",
    "# Console handler for logging to the terminal\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "console_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\"))\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# GDELT API endpoint for the Global News API (event data)\n",
    "url = \"https://api.gdeltproject.org/api/v2/doc/doc\"\n",
    "\n",
    "# Topics to search for with lowercase query for GDELT\n",
    "topics = [\"election\", \"business\", \"finance\", \"health\", \"environment\"]\n",
    "\n",
    "# Directory for saving files\n",
    "save_directory = \"data\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Prepare the final list of processed articles\n",
    "all_articles = []\n",
    "\n",
    "# Fetch articles for each topic\n",
    "for topic in topics:\n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        \"query\": f\"{topic} sourcecountry:unitedstates sourcelang:english\",  # Topic in lowercase for query\n",
    "        \"startdatetime\": \"20241006000000\",  # Start date (6th Oct, 2024)\n",
    "        \"enddatetime\": \"20241105235959\",    # End date (5th Nov, end of the day)\n",
    "        \"mode\": \"artlist\",                  # Get article list mode\n",
    "        \"format\": \"json\",                   # Get JSON format\n",
    "        \"maxrecords\": 250,                  # Maximum number of records to fetch (adjust as needed)\n",
    "    }\n",
    "\n",
    "    # Send the request to the GDELT API\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an HTTPError if the response code is not 200\n",
    "        logging.info(f\"Data fetched successfully for {topic} from GDELT API.\")\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract articles from the data\n",
    "        articles = data.get('articles', [])\n",
    "\n",
    "        # If no articles are found, log and skip\n",
    "        if not articles:\n",
    "            logging.warning(f\"No articles found for topic: {topic}\")\n",
    "            continue\n",
    "\n",
    "        # Process each article\n",
    "        for idx, article in enumerate(articles):\n",
    "            # Generate a random 9-digit ID for the article\n",
    "            article_id = random.randint(100000000, 999999999)\n",
    "\n",
    "            # Get 'fromdate' and 'todate' or skip if not available\n",
    "            fromdate = article.get('fromdate')\n",
    "            todate = article.get('todate')\n",
    "            \n",
    "            # Format dates if they are available, else default to start and end date in range\n",
    "            if fromdate:\n",
    "                fromdate = f\"{fromdate[:4]}/{fromdate[4:6]}/{fromdate[6:]}\"\n",
    "            else:\n",
    "                fromdate = \"2024/10/06\"\n",
    "            \n",
    "            if todate:\n",
    "                todate = f\"{todate[:4]}/{todate[4:6]}/{todate[6:]}\"\n",
    "            else:\n",
    "                todate = \"2024/11/05\"\n",
    "            \n",
    "            processed_article = {\n",
    "                'id': article_id,               # Unique random ID\n",
    "                'category': topic.capitalize(),  # Capitalized category name for output\n",
    "                'fromdate': fromdate,           # Use actual 'fromdate' or default with updated format\n",
    "                'todate': todate,               # Use actual 'todate' or default with updated format\n",
    "                'sourcename': article.get('domain', 'N/A'),\n",
    "                'title': article.get('title', 'N/A'),\n",
    "                'url': article.get('url', 'N/A'),\n",
    "                'seendate': article.get('seendate', 'N/A'),\n",
    "                'sourcecountry': article.get('sourcecountry', 'N/A'),\n",
    "                'language': article.get('language', 'N/A'),\n",
    "            }\n",
    "            all_articles.append(processed_article)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error while fetching data for {topic}: {e}\")\n",
    "        print(f\"Error while fetching data for {topic}: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error while fetching data for {topic}: {e}\")\n",
    "        print(f\"Unexpected error while fetching data for {topic}: {e}\")\n",
    "\n",
    "# Convert to a pandas DataFrame for easy CSV conversion\n",
    "df = pd.DataFrame(all_articles)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(f\"{save_directory}/all_articles_2024-11-05.csv\", index=False)\n",
    "logging.info(\"CSV data saved successfully for all topics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
